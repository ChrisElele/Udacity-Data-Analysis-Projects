# Udacity-Data-Analysis-Projects
This repository is for all the major projects I worked on during the course of my Udacity Data Analyst Nanodegree program.

The Udacity online data analyst program prepared me for a career as a Data Analyst as it helped me to learn how to clean, tidy and organize any data. It also aided me in discovering patterns and getting insights which were used to draw meaningful conclusions, and clearly communicate critical findings through visualisations. I am now using the skills garnered from this program to build a portfolio of projects.

**Tips:** For data analysis projects with python, I highly recommend installing basic libraries like numpy, pandas, matplotlib, seaborn, scipy.

## Part 1 - Intro to Data Analysis
**Courses Covered:**

- Anaconda: Learned to use Anaconda to manage packages and environments for use with Python
- Jupyter Notebook: Learn to use this open-source web application
- Data Analysis Process
- NumPy for 1 and 2D Data
- Pandas Series and Dataframes

**Project 1: Investigate a dataset called TMDb movie data.**
In this project, I chose one of Udacity's curated datasets called TMDb movie data, and investigated it using NumPy and pandas. I completed the entire data analysis process, starting by cleaning my data, then posing several questions, and finishing by sharing my findings.

## Part 2: - Data Extraction and Wrangling
**Courses Covered:**

- **DATA GATHERING:**

    - Gathered data from multiple sources, including gathering files, programmatically downloading files, web-scraping data, and accessing data via APIs.

    - Imported data of various file formats into pandas, including flat files (e.g. TSV), HTML files, TXT files, and JSON files

    - Store gathered data in a PostgreSQL database.

- **DATA ASSESSMENT**

    - Conducted visual and programmatic assessment of data using pandas
    - Distinguished between dirty data (content or “quality” issues) and messy data (structural or “tidiness” issues)
    - Identified data quality issues and categorised them using certain criteria: validity, accuracy, completeness, consistency, and uniformity
    
- **DATA CLEANING**

    - Identified each step of the data cleaning process (define, code, and test)
    - Cleaned data using Python and pandas
    - Assessed dataset visually and programmatically using Python
    
**Project 2 : Wrangle and Analyse the WeRateDogs Twitter data**

I collected data from different sources and assessed the data visually and programmatically , cleaned the dataset and then analysed and visualised insights drawn from the data. I carried out all the cleaning operation in my jupyter notebook using pandas and numpy. I also analysed and visualised the data in my Jupyter notebook.



## Part 3 - Data Visualization
**Courses Covered:**

- Univariate exploration of data ( histogram , bar charts , Use axis limits and different scales )
- Bivariate exploration of data ( scatter plots , clustered bar charts , violin and box plots , faceting )
- Multivariate exploration of data ( encodings , plot matrices , feature enginnering )
- Explanatory Visulizations ( story telling with data , polish plots , create slide deck, README.md )

**Project 3: Data Visulization and Communicating Data findings with Prosper Loan Data**

In this project, I used Python’s data visualization tools to systematically explore the Prosper Loan dataset in order to find out the features that determine a borrower's APR and loan perfomance. Then, I created a presentation that communicates the findings to my audience.
